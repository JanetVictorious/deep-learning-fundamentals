{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification with Keras Sequential model\n",
    "\n",
    "In this notebook we will build a binary classification model utilizing the [Keras Sequential model](https://www.tensorflow.org/guide/keras/sequential_model).\n",
    "\n",
    "The sequential API is well suited for building models with layers that proceed in a sequential manner. This entails that the order of the layers matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 23:16:55.576211: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-16 23:16:55.630935: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-16 23:16:55.632170: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-16 23:16:56.551902: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/hojve/repos/github/deep-learning/deep-learning-fundamentals/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from simple_keras import KerasSeqClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We start by loading the `MNIST` dataset which contains images depicting hand-written numbers from 0-9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "split = ['train[:50%]', 'test[:50%]', 'test[50%:]']\n",
    "\n",
    "# Load mnist dataset\n",
    "(ds_train, ds_eval, ds_test), ds_info = tfds.load(\n",
    "    name='mnist',\n",
    "    split=split,\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect dataset\n",
    "\n",
    "Start by inspecting the data. A TensorFlow `Dataset` has a lot of properties, for reference see [TensorFlow Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Datasethttps://www.tensorflow.org/api_docs/python/tf/data/Dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "5000\n",
      "5000\n",
      "(TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Print info\n",
    "print(len(ds_train))\n",
    "print(len(ds_eval))\n",
    "print(len(ds_test))\n",
    "print(ds_train.element_spec)\n",
    "\n",
    "# Calculate number of classes in label\n",
    "num_classes = ds_info.features['label'].num_classes\n",
    "print(num_classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize some of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 23:16:58.335981: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-16 23:16:58.336930: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-05-16 23:16:58.384394: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-05-16 23:16:58.384867: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-16 23:16:58.578354: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-05-16 23:16:58.579716: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn4AAAKSCAYAAABMVtaZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyPElEQVR4nO3de5zVVb0//rVnuF8FlJuKgwKaKFomiKXR6aJdMM1baRcM046iWWZ+K80TpV0swyQ1yyRTzEulUpmp5QVFvGFeQkEFFBAEFAFhkJnZvz/OOf6OutbkHvfMntnr+Xw8+Oe9Hu/P581lz7z4wFqfQrFYLAYAAKpeTaUHAACgbQh+AACZEPwAADIh+AEAZELwAwDIhOAHAJAJwQ8AIBOCHwBAJgQ/AIBMCH4AAJkQ/Nqhs88+OxQKhbDbbrtVehSoKhs2bAhnnXVWOPDAA0P//v1DoVAIM2bMqPRYUHU2b94cTj/99DB06NDQvXv3MG7cuHDLLbdUeiyC4NfuLF26NJxzzjmhZ8+elR4Fqs7q1avD1KlTw/z588Mee+xR6XGgak2aNCmcd9554eijjw7nn39+qK2tDR/96EfD7NmzKz1a9grFYrFY6SH4/33qU58Kq1atCo2NjWH16tXhscceq/RIUDU2b94cXnrppTB48ODwwAMPhL333jtcdtllYdKkSZUeDarGfffdF8aNGxfOPffc8LWvfS2EEEJ9fX3YbbfdwsCBA8M999xT4Qnz5olfO3LnnXeG6667LkybNq3So0BV6tq1axg8eHClx4Cqdt1114Xa2tpw3HHHvVbr1q1bmDx5cpgzZ0547rnnKjgdgl870djYGE466aRw7LHHht13373S4wBAi8ybNy+MGjUq9OnT53X1sWPHhhBCePjhhyswFf+rU6UH4L9dfPHFYcmSJeHWW2+t9CgA0GLPP/98GDJkyJvq/1tbvnx5W4/E/+GJXzuwZs2a8O1vfzuceeaZYZtttqn0OADQYps2bQpdu3Z9U71bt26vrVM5gl87cMYZZ4T+/fuHk046qdKjAMDb0r1797B58+Y31evr619bp3L8U2+FLVy4MFxyySVh2rRpr3v8XV9fH7Zs2RIWL14c+vTpE/r371/BKQHgrRkyZEhYtmzZm+rPP/98CCGEoUOHtvVI/B+e+FXYsmXLQlNTUzj55JPD8OHDX/sxd+7csGDBgjB8+PAwderUSo8JAG/JnnvuGRYsWBDWrVv3uvrcuXNfW6dyPPGrsN122y388Y9/fFP9jDPOCOvXrw/nn39+2GmnnSowGQCU7rDDDgs//vGPwyWXXPLaOX6bN28Ol112WRg3blzYfvvtKzxh3gS/Ctt6663DwQcf/Kb6/57lF1sDWm769Olh7dq1r/3XilmzZoWlS5eGEEI46aSTQt++fSs5HnR448aNC4cffnj4xje+EV544YUwYsSI8Jvf/CYsXrw4XHrppZUeL3ve3NFOTZgwwZs7oBXU1dWFJUuWRNcWLVoU6urq2nYgqEL19fXhzDPPDFdccUV46aWXwpgxY8J3v/vdcMABB1R6tOwJfgAAmbC5AwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyIfgBAGRC8AMAyMRbfnPHh2oOb805oCJuabq20iO8ic8a1chnDdrGv/useeIHAJAJwQ8AIBOCHwBAJgQ/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyIfgBAGRC8AMAyITgBwCQiU6VHgAAyFNhr9HJtT7nr4jWrxp+S7Jnt3s+H63XTXom2dP0yivJtWrkiR8AQCYEPwCATAh+AACZEPwAADIh+AEAZELwAwDIhONcAICKeH7/vsm1WcMvj9abmrneI/vOiNZHX3pMsmenSQvi96mvb+ZOHZcnfgAAmRD8AAAyIfgBAGRC8AMAyITgBwCQCbt6q9yaL45Prs39r59H63uePyXZM/RH97ztmaAjq+ndO1pfctkOyZ5e3TdH6/0mpl8cH5oaS5oL2rN1n94nWr/2lHOb6epWtvs/vt9lybXdvxn/nrfDt+eU7f7tiSd+AACZEPwAADIh+AEAZELwAwDIhOAHAJAJwQ8AIBOOc6lyPQ5bkVxrCsVofXO/eB2yUSgkl5Zevn20/ujY+Avlm3PA/scm12pvf6jk60El1fbpk1zb/+v3RuvDO5XvyJaW+v3nzovWv/rt9HFoHZknfgAAmRD8AAAyIfgBAGRC8AMAyITgBwCQCbt6q0TtrqOi9T/smn4x9RkvvCdaHzFjVbLHa+PJQXGfMcm1h8emP1MpTzdsita7PL8u2eOzRkfTaVaP5No5A2+P1ptacJ/vrU5/Ps/Y+pGSr9ejkNenzRM/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMiE4AcAkAnHubxRMy9nTyoWyz9HieZ/pW+03rcm/QLsvy+LHwHT/8kFZZkJOqqnj+he1uvdsD5+/ETjk0+V9T7QFpaftm+0/o8dz22mq/TP1FXrB0Xr908YmOw58oYDo/Wrd/prsqdnTfz7fs0e70j2NP1zfnKtvfPEDwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyYVfvG7zyybHJtY+edXu0fsvX90/2dPnr/W93pLdkr10Wldzz8mMDovX+b3cY6OD+dMh5zazGd8pvKr6a7Jh50QHR+sBwTyljQZtZ8eX4zt0QQrjz5B9H672aOUUi5fJ12ybXfn/Y+6L1xpeeTPYsXrtzyTP0S8y99EP9kj1D/1nybdoNT/wAADIh+AEAZELwAwDIhOAHAJAJwQ8AIBOCHwBAJhzn8gadNjYl104b8K9ofcb7/iPZMzz9XuiS1Y7aKbl26fArovVFDemfz8hLno/WG0obCzqs2kHxl72P6lz6sRRzN/dMrg38uWNbaJ9qR+4Yrf/n8Tcke3rVdC35PrfXd47WZ3zzE8meHo/PLfk+5dR5/zXpxfiJNh2CJ34AAJkQ/AAAMiH4AQBkQvADAMiE4AcAkAm7et+g+7L1lR4hafGRg5JrvQrxXVbfemF8sqfhmcVvdyTo0J744fZlu9YFSz/YzOrKst0HStXciRDv/8PD0frkvs+WdYYplx8frQ/7Y/vd8X7k8IeSa38P6V387Z0nfgAAmRD8AAAyIfgBAGRC8AMAyITgBwCQCcEPACATjnN5g80D2+8W7U1DGkru+cvcPZNrI0NlX4ANlXbvB36WWOle8rVW/mJ4cq2P41yooG6/WpdcO6XfgrLd53urxyTXhl+4MFpvLNvdy++yP3woubZDaL/H0Pw7nvgBAGRC8AMAyITgBwCQCcEPACATgh8AQCbs6n2DxQenf0lqQqFNZqgduWO0fvPHfpruKcR3I+/8y/RurqbSxgJCCE9s2Ryt9702/UL3YmsNA//H+k/tE63/ZacLm+kq/fva840bo/X7j3hHsqdx1VMl36clCoX4p60l3787b3i707RPnvgBAGRC8AMAyITgBwCQCcEPACATgh8AQCYEPwCATGR7nEtNjx7R+rUfuyDZ0xRqo/VJH/t7sufXw/aN1vtvld4n/oXh8Zc/D+/ULdnznVW7RutNj5bvBdzQETW9753JtV6F+0q+3sQbT4nWR26ZW/K1oFS1gwYm1779vcui9aYWHCi0tGFTcu3wqadF6wOenFPyfVqiplv6e+HO/VdF6839GmwubonWey2rzkPPPPEDAMiE4AcAkAnBDwAgE4IfAEAmBD8AgExku6t32Zf2jNbHdLmr5GudNuBfybXTJ8yP1luyy6o5N174vmh966a22WUF7VXf7z2XXOtR0yVa39BUn+x5x09XROsNpY0FLVLont7R+oHuG8t2n08+fGxybeCllf2+8sy30jv1H6ubXvL1VjXGP719Zt5b8rU6Ak/8AAAyIfgBAGRC8AMAyITgBwCQCcEPACATgh8AQCayPc7llXfFX0C9sjH9Yur9bvtytN55RfxIiBBC6PpSIV5fkz7OZc7U0rejD/r9gmi9seQrQcdUu+uoaH3aDr9O9jQWe0Trv1k3MtnTsGhJaYNBC2z6xNho/Vc/+2kzXemjXlKaQlN84Zb+JV+rrYz74ONlvd5WNfFnYA0f2CvZ0+m2B8s6Q1vyxA8AIBOCHwBAJgQ/AIBMCH4AAJkQ/AAAMpHtrt4Rn5kXrU8O7032jArl28Wz5ovjk2s1Ib4TeP9HD0v29Fr9zNueCTqyJ/5fr2h9SG18525zLvnlxOTa4HBPydeDUk08+7ZofXin0nfuNueq9dtG6wOnV/7P+SuHjovWL9z+/Ga6Opd8ny0hfspGl9Ubkz2JvdAdgid+AACZEPwAADIh+AEAZELwAwDIhOAHAJAJwQ8AIBPZHudSaT0OW5Fca0psLV81b1Cyp1dwnAt5m/Ku28t2rcE/rfxRFuTtFzd9OFo/5agFZb3P1L8dEq2PDHPLep+UlSftm1w7bcrV0XrXQulHtjRnv8u/Fq3X/XNOWe/TXnjiBwCQCcEPACATgh8AQCYEPwCATAh+AACZsKu3QqbvfFVyrSnURuvb3tHQWuNAh9C03zuTa5O3ujCx0jXZ8/7HDo3Wu4dFpYwFZdf9hUKb3KfYJX6KxPKvpXfbbtxzU7Res6xbsmf38U9F67cOPzfZ07cmfb2ULcXGaP09D34u2VN35n0l36cj88QPACATgh8AQCYEPwCATAh+AACZEPwAADIh+AEAZMJxLq2s8f3vitZ7FmYnew5dGH9pdpe/3l+WmaCjGnne/ORar0L62JaUruds9TamgY5vwcSL2uQ+nQvxY8q2FEs/suXu+s7JteOvmhKt150xp+T7VCtP/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE3b1trL+310Srdd16pHsuXLEH6L1fb9xarJnu+/fU9pg0I7V9usXrR/a/86Sr/X4lleTa53mxncJN5V8Fyiv7f/4fLT+80k7JXtO3Orp1hrnbWssxj9VD25O9xz15xOi9V0uXpvsqXvc7t1/xxM/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMiE4AcAkAnHubSypmIhXg/FZM+0NXtF63VXPJvsaShtLGjXXt1zeLQ+odttJV/r688cmlwr1i8r+XrQFhqfWhSt3/KBnZM9vzzmo9H6z4+9ONnznm5bShusGbvfPSm51vuvvaL1gf9YnuwZuWhutN5Y0lS8kSd+AACZEPwAADIh+AEAZELwAwDIhOAHAJAJu3pb2bFD7orWlzZsSvbMPWr3aL3xuSfLMhO0d4smdinbtV68fFhyrV+wq5eOpWHFyuTadt+Pr33/+2Naa5zX2SE8WnKPEynanid+AACZEPwAADIh+AEAZELwAwDIhOAHAJAJwQ8AIBOOc2llg2vXRet3bapL9jQ+7tgW8rbLec9F6/cfXEz2NIZCtL719f9qpgcgL574AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAm7OptZacPH1fpEaDDaVi6LFo/a8e9WnC1l9/eMABVxBM/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyIfgBAGRC8AMAyITgBwCQCcEPACATgh8AQCYEPwCATAh+AACZEPwAADJRKBaLxUoPAQBA6/PEDwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyIfgBAGRC8AMAyITgBwCQCcEPACATgh8AQCYEPwCATAh+AACZEPwAADIh+AEAZELwawcmTZoUCoVC8seyZcsqPSJUhYULF4ZPfepTYbvttgs9evQIu+yyS5g6dWrYuHFjpUeDqrJhw4Zw1llnhQMPPDD0798/FAqFMGPGjEqPRQihU6UHIITjjz8+fPCDH3xdrVgshi996Uuhrq4ubLvtthWaDKrHc889F8aOHRv69u0bpkyZEvr37x/mzJkTzjrrrPDggw+GG264odIjQtVYvXp1mDp1ahg2bFjYY489wu23317pkfgfgl87MH78+DB+/PjX1WbPnh02btwYjj766ApNBdXlt7/9bVi7dm2YPXt2GD16dAghhOOOOy40NTWFyy+/PLz00kuhX79+FZ4SqsOQIUPC888/HwYPHhweeOCBsPfee1d6JP6Hf+ptp2bOnBkKhUI46qijKj0KVIV169aFEEIYNGjQ6+pDhgwJNTU1oUuXLpUYC6pS165dw+DBgys9BhGCXzu0ZcuWcM0114R999031NXVVXocqAoTJkwIIYQwefLk8PDDD4fnnnsuXH311eGiiy4KJ598cujZs2dlBwRoA/6ptx26+eabw5o1a/wzL5TRgQceGL773e+Gc845J9x4442v1b/1rW+F733vexWcDKDtCH7t0MyZM0Pnzp3DEUccUelRoKrU1dWF/fffPxx66KFhwIAB4c9//nM455xzwuDBg8OUKVMqPR5AqxP82pkNGzaEG264IRxwwAFhwIABlR4Hqsbvfve7cNxxx4UFCxaE7bbbLoQQwic/+cnQ1NQUTj/99PDpT3/aZw6oev6PXztz/fXX280LreDCCy8M73znO18Lff/roIMOChs3bgzz5s2r0GQAbUfwa2euvPLK0KtXr3DQQQdVehSoKitXrgyNjY1vqm/ZsiWEEEJDQ0NbjwTQ5gS/dmTVqlXh1ltvDYccckjo0aNHpceBqjJq1Kgwb968sGDBgtfVr7rqqlBTUxPGjBlTockA2o7/49eOXH311aGhocE/80IrOO2008JNN90U9ttvvzBlypQwYMCA8Kc//SncdNNN4dhjjw1Dhw6t9IhQVaZPnx7Wrl0bli9fHkIIYdasWWHp0qUhhBBOOumk0Ldv30qOl61CsVgsVnoI/tv48ePDM888E5YvXx5qa2srPQ5Unfvuuy/813/9V5g3b15Ys2ZNGD58ePj85z8fvv71r4dOnfw9GMqprq4uLFmyJLq2aNEi59RWiOAHAJAJ/8cPACATgh8AQCYEPwCATAh+AACZEPwAADIh+AEAZELwAwDIxFs+sfRDNYe35hxQEbc0XVvpEd7EZ41q5LMGbePffdY88QMAyITgBwCQCcEPACATgh8AQCYEPwCATAh+AACZEPwAADIh+AEAZELwAwDIhOAHAJAJwQ8AIBOCHwBAJgQ/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyIfgBAGRC8AMAyESnSg8AUA1qB/RPrj112s7R+vzP/jzZc3t952j9J/v8R7KncdWq5Bq0RzU9eiTX9rpnfbT+6a3uS/Z8+ZgTo/XafzxU2mBVzBM/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMiEXb1Ah1EzZpfkWkPf7tH604d1TfYUuzZF60PrVid7PjzkiWj96oVDkz2Pj58ercfv/t8mdNsSrZ/XM/7zDCGEYFMvHUzNoG2Sa9/ZZnZiJf2ZPuCCO6L1v48dlOxp2rgxuVaNPPEDAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmXCcyxsMmtMnuXb5DndG68NvOC7ZM+o/0y+ThhykXsJeHL1Tsmfgz5ZE62cMvTTZs1On+DEnTaHYzHSlqwmFaP2bWz9a1vtADp48u19Zrzey68po/R/b7ZluWvB0WWdo7zzxAwDIhOAHAJAJwQ8AIBOCHwBAJgQ/AIBMVPeu3kJ8910IIRTevVu0fsbQi5M9W4rdovX7P/7TZM/Yxq9G68P/0JCerRjfhdhlXuk7j9YctGtybd3w+K9P7yXpXZD9r3ooWi9u3lzaYFSVmjG7JNf2uvzxaP2sbWa04E7xz2AIIZyw7D3R+uzndkxf7eb4Lv5ua9OfgTt/emFyrZxu2xR/EX3xlU1tcn8opzWTx0frT024KNnT2IIN+b9atl/8Wpnt3G2OJ34AAJkQ/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE1V9nEvTe/ZIrv3l6tTL3tPHRaT0rUn3PHlI4uiHQ0q+TQv9vaxXO+5LE6L1Fw7eKtnTsCL+0mw6npeP3idav/tHpR9xsrghfSzJsQuOjtaL0wYme7r++f5ofbsQP06mOStP3rfknmeb+fmk1HXqkVz7yj+PiNa3W1X6zwcq7eVR5btW6qijEEIoHtOlfDeqUp74AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmqmJXb+2u8e1Ck3/9x7Le56ktm6P1Lc3k59Gd4zuMmkLpb5+uCYXkWkuut2DLq9H6qMTMIYTwq+3viPf8eHKyZ8Rn7OrtSIrj07vhb/7hT6P1ppD+M3PainHR+oJPDUv2dFn4TGJlSbKnnAbdtyG5NvK2Y6P1TsvSOw0vO/Ln0fqwTunP7bBJz0brTckOaL9OnXhj2a51wvXp7zc7Lbq3bPepVp74AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmBD8AgExUxXEuT5zQL1o/pOeLJV9r5+tPSK6940fLo/XihleSPasn7lzyDG1lwLy10fqNf7mi5Gv17FX/NqehvVj1zp7JtR6F0l+AvvBjA6L1xhWpI1vagXsfSS6NTJwW8cIJ+yZ7xnaNH9uysnFTsqdp/frkGrRHzX0Gjul7fmKlc8n36bnMM6u3w68eAEAmBD8AgEwIfgAAmRD8AAAyIfgBAGSiw+zqrZ84Nrl290E/Sax0L/k+7/jxiuRaw5LnSr5evxlzSu5pK8V3ji65pynEdyf+ao/Lkz1n9ZwQv9Yr6d3QVM7aMQ3lvd5+ddF6r2tXlvU+lXbw8beX3PO+338tuTYieNk8HcuxU2Yl1zqF2pKvd//m+PebbX/7ZLKnseS75McTPwCATAh+AACZEPwAADIh+AEAZELwAwDIhOAHAJCJDnOcS/fl6aM/tq6NH9vyclN9smfvv5wSre+y8vGS5urInvpM75J7akIhWj/2n59L9gx5ZX7J96FyRly5JblWMzH++9+cO6ddFF+Ylu458IlPROvPv9wn2fPKyp7R+g43xo+ECCGErjfdnx4iYcUp8RfRn7H19GTPXfXxF9GP+IojW6geu3cr/ciz5nzuminR+vDV7feYtI7AEz8AgEwIfgAAmRD8AAAyIfgBAGRC8AMAyESH2dVbfOhfybWJB0+K1mvWpncCj1oY383XVNJUHVtj79JfZ90U0jskqQ6196U/a+897YRo/cDT70z2jOi2Mlo/otcLyZ6/7HJ9ci0lteN8w8TNyZ55m+M7gZuzc+fZ0XpTiJ8uEEIIs9buGe/Zb49kT81d80qaC9rKypPjO9vHd32wma7453Npw4Zkx45nPRSt+y709njiBwCQCcEPACATgh8AQCYEPwCATAh+AACZEPwAADLRYY5zCcX0Bu7i/Y9G66UfVlJ9Fp6/T3Lt/o/8JLHSLdmzqKE+Wu/7mz6ljEU7VtycPv6kz8x7o/V7ZnZJ9swdED+yZMY7hiV7Fk+MH43S0Le8n+orPnxxtD62a/rrTU3oEa03d9TRDwbHj48Kv0vUQwjnrtk1Wv/z996f7Ol1Tfz3B8qp8f1ro/XOhdqSr7W+Kf38qbmvRbScJ34AAJkQ/AAAMiH4AQBkQvADAMiE4AcAkImOs6uXZi28YFy0Pv+TFyR7aprZvZtywM2nROuj/ji35GuRh8Y1L0brNbPj9RBC2HF2+e6/4fD4ZyOEELb5yKbESvqzceYLe0brN1/8nmRP/YfXRes/3eOaZM/pA+ZH64edG39xfQghfPmJydF60yNPJHsgpnHCu5Jr17xzerynWPr3lIOuPjW5tmOYU/L1+Pc88QMAyITgBwCQCcEPACATgh8AQCYEPwCATAh+AACZcJxLe1QoRMsrp4xPttx78LnRekuObDl60YeTazuf+M9oPf16emgbT/10n2h99qE/TvYMrO0RrZ+wLH00y7PH7hCtb/1IM0dP/CJePvvjxyRbPvCLi6P1nTp1T/Y09Il/3v0Nn1K9NKprcm1U59K/r6TUzUodqURr8fUAACATgh8AQCYEPwCATAh+AACZEPwAADJhV2+F1I7eObn27Hfjvy3/HBd/MXYIITS1YPfuJS/XResbvrBVsqe4ZU3J94FSFbrGdxTW/HVAsmfBqAuj9aaQ3gX7rvuPjta3/eLqZE/TqieSa6V64V2lfwk+76WRybXauf+K1u26p71avl98Z30IIWw3uw0HyYgnfgAAmRD8AAAyIfgBAGRC8AMAyITgBwCQCcEPACATjnNpZcV994gvnL0q2TNv1KxovakF95/w6OHJtb6ndo7WGxc82YI7QVyn4TtE64uO3jbZs99B86L19/S5L9nzUlP8Ze/jrjs12TPq249H643r1yd7WqJ2q77R+pc/dUPJ15p54QHJtYFb7in5ehDT/ZMr2+Q+N/3nj5JrX/z+e9tkhtx44gcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmbCrtwxqR+6YXBs9/ZFo/ZxBD5R1hj1/flK0vt056V1+jWWdgBzU9O4drS+5LL5zN4QQHh1/ebTeFIol3//Ipw9Mrv3st/Ed7CN+OSfZ05Kd8i2xcfyoaH1y378ne27b1C1aH3LtwmSPzzTlcuDQf1V6BFqJJ34AAJkQ/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE45zKYP5p26dXJs16LpovbljJJ5tiL9s/qBffD3Zs/1PHozWSz8wg9y9esC7k2vjf3BftP6ngfEjW0IIobYQ//vliD99Mdmz67efjdYbVqRfHD8grEqutYXad4xMrv3sogui9ZrQJdnz1V/Gf322XZU+ogk6mo89eFxybWhwpExr8MQPACATgh8AQCYEPwCATAh+AACZEPwAADJhV28JFv5sXLT+8MenJXuaErv2Fmx5Ndlz5MXx3bvb/SC9m8/uXcpl8SHpvw/+beC8aL25XeqhGF/ttaBzuqVfn/h9Rg5t7k5tYvl+3aP1H33h18med3SO/1yvXD8w2bPtD+3epfVtOnhstH5iv2nNdHUr+T4/XPOOaH3oIXbutjVP/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmHOfyBrWD0scrnHPANdF6j0L6Res1oRCtHzT7hGTPiGaObYHWNmpGfXLt0v2HReuT+z5b8n0e+soFybXHT2yI1kd3SX/JSn3Wmsp82FHqPuua0r9uH3/iiGi99oiNzdzpxVLGghbZ0iP+/KdPTelHtjTnV3dOiNZHhrllvQ//nid+AACZEPwAADIh+AEAZELwAwDIhOAHAJAJu3rfYMkXRiTXDu11U8nX+92GbaL1naeuS/Y0lnwXKKN7H0ku3fDuHaL13358YrJnxfh4vduw9cment1ejdbv3vN3yZ6WuOClkdH6pU8mhg4hbHyhZ7Red0N693CXv94frfusU2l9r30oWt9txJRkz7D3xXfxL1gyONkz5K74bnjanid+AACZEPwAADIh+AEAZELwAwDIhOAHAJAJwQ8AIBOOc3mDPkuakmsteQn89399ZLS+7YJ7ShsM2oGmjRuj9V7X3JvsGXFN+e7/8bBX+S7WjO3C421yH6i04pb40UnDppb+PWpUWPp2x6ENeOIHAJAJwQ8AIBOCHwBAJgQ/AIBMCH4AAJmwq/cNtro+/YL6U08dG61/ccBdyZ7tb14braf3DgMAtA5P/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmHOfyBqmX0IcQwvzE++G/GsY3c8V/vb2BAADKxBM/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyIfgBAGSiUCwWi5UeAgCA1ueJHwBAJgQ/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyIfgBAGRC8AMAyITg1w7cf//9YcqUKWH06NGhZ8+eYdiwYeGII44ICxYsqPRoUFUmTZoUCoVC8seyZcsqPSJUhQ0bNoSzzjorHHjggaF///6hUCiEGTNmVHosQgiFYrFYrPQQuTvssMPC3XffHQ4//PAwZsyYsGLFijB9+vSwYcOGcO+994bddtut0iNCVZgzZ054+umnX1crFovhS1/6UqirqwuPP/54hSaD6rJ48eIwfPjwMGzYsLDjjjuG22+/PVx22WVh0qRJlR4te50qPQAhfPWrXw0zZ84MXbp0ea125JFHht133z384Ac/CFdccUUFp4PqMX78+DB+/PjX1WbPnh02btwYjj766ApNBdVnyJAh4fnnnw+DBw8ODzzwQNh7770rPRL/Q/BrB/bdd9831UaOHBlGjx4d5s+fX4GJIB8zZ84MhUIhHHXUUZUeBapG165dw+DBgys9BhH+j187VSwWw8qVK8PWW29d6VGgam3ZsiVcc801Yd999w11dXWVHgeg1Ql+7dSVV14Zli1bFo488shKjwJV6+abbw5r1qzxz7xANgS/duiJJ54IJ554Yhg/fnz4/Oc/X+lxoGrNnDkzdO7cORxxxBGVHgWgTQh+7cyKFSvCxz72sdC3b99w3XXXhdra2kqPBFVpw4YN4YYbbggHHHBAGDBgQKXHAWgTNne0Iy+//HL4yEc+EtauXRvuuuuuMHTo0EqPBFXr+uuvt5sXyI7g107U19eHiRMnhgULFoRbb7017LrrrpUeCaralVdeGXr16hUOOuigSo8C0Gb8U2870NjYGI488sgwZ86ccO21177pnDGgvFatWhVuvfXWcMghh4QePXpUehyANuOJXztw6qmnhhtvvDFMnDgxvPjii286sPkzn/lMhSaD6nT11VeHhoYG/8wLrWj69Olh7dq1Yfny5SGEEGbNmhWWLl0aQgjhpJNOCn379q3keNnyyrZ2YMKECeGOO+5IrvstgvIaP358eOaZZ8Ly5cttoIJWUldXF5YsWRJdW7RokbMzK0TwAwDIhP/jBwCQCcEPACATgh8AQCYEPwCATAh+AACZEPwAADIh+AEAZOItv7njQzWHt+YcUBG3NF1b6RHexGeNauSzBm3j333WPPEDAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyIfgBAGRC8AMAyITgBwCQCcEPACATgh8AQCYEPwCATAh+AACZEPwAADIh+AEAZELwAwDIhOAHAJAJwQ8AIBOCHwBAJgQ/AIBMCH4AAJkQ/AAAMiH4AQBkolOlB6iUhZe/K1r/+K6Plnytv9yxV3Kt53PxbN1zRVOyp/fv7i15BgDIXWHv3aP1q/7wi2TPt1b8R7T+9N71ZZmpvfHEDwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyURW7emt69IjWn7lsRLJn4Xt/Vbb7/+zT9yfXGovx3bsNoTHZ883TxkXrc340NtnT+2o7gQHI27IJvaP1roV03Dlpm79H61/dY3Kyp+mf80sbrB3xxA8AIBOCHwBAJgQ/AIBMCH4AAJkQ/AAAMiH4AQBkoiqOc1k4dUy0/uR7L2yT+6eObGlOp1CbXPvR4Aei9Su/82yy5zerPxG/z20PljYYZGTTJ+JHJB343TuSPcf1eyhaf9+FpyV7tvv+PaUNBiS9fPQ+ybUfHP/raL1HTZdkz/LG7tF6YePm0gbrIDzxAwDIhOAHAJAJwQ8AIBOCHwBAJgQ/AIBMVMWu3jCk9J03+z96WLS+8rGByZ5OGwvR+k6XpHfbFrt3jdYH/XZVsueC7W6J1o/u/UKyZ9F5c6L1OXv1SM/W0JBcg9ZW269fcq346qvReuOYEcme1XvE/6y/NC5+rRBCmLzXndH6aQP+lewJoVu0WjN2bTM9QKkKneIRZavJzyV7PtajPlrfXNyS7DnlkaOi9aELm/s60HF54gcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyURXHuQy/qBit7/Lcicmenc64P1rv1fBMyfdvyaEoy9PvmA6fueMT0frvR9yU7Dlj68ei9d1Pn5Ls2f5sL46nNLV9+kTrg/4W/ww2Z/2W2uTaEYPif57363Zzsmfr2viL1mtC/BimEEJoCqXPnbJxQ/zoJqBlFkzbK1p/ZpdflHyt01eMT64NPaQ6j21J8cQPACATgh8AQCYEPwCATAh+AACZEPwAADJRFbt6a2Y/HK3vODvdU769fOX30o93iNbXXRh/+XQIIfSpib84/peTpyd7zv7DkdF64/yFzUxHzgq9e0Xrl2w/K9mT2lXbkh21qxvTa882bIrWP3jbKcme3v1fidbvefdlyZ6uhc7RetOr6V3KQMLY3ZNLdx/0k8RK/OtQCCFsLm6J1uf+5N3Jnj7h3uRapTV8IL6zudNtD7b4mp74AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmBD8AgExUxXEu1abbrPui9b0+9JVkz8JDL4rW92nmvfEbRvWL1rvPT/eQt6Y1L0br+3/txDa5f5+n48evhBBC7YsbovVRTz1Q8n2unl+XXPtcn2XRes16X04hpbZPn2h95Zmbkz1DOqWPbUnZ+/7Pxa81s/0e2dKcTq/Ej6d5OzzxAwDIhOAHAJAJwQ8AIBOCHwBAJgQ/AIBM2IbWgdTd2JBePLT0663eLf7bv/0NpV+LPDTV10frfa6q/I65xhb01A4aGK1v3/nxZE9NKETrPZ/z92hIWXHU6Gj9ob3iJ1I055FX41+HQgih36W9S75eu3bvI2W/pK9UAACZEPwAADIh+AEAZELwAwDIhOAHAJAJwQ8AIBOOc8nYqA8/Ha3X/zD9x6LY0MyRMtDBbNpzWLT+/u7p4yKaEvXie9emb/STtz4TdFQbDxmXXLvtW6kPQY9kT2Mx/mn77LSvJnsGz7onucZ/88QPACATgh8AQCYEPwCATAh+AACZEPwAADJhV28H0m35+uTag6/GX1G/V5faZM/hgx+I1q/ovmuyp7g+PQN0NKvHdCnbtV79V9+yXQs6oh1OezK51q82vXs3ZeQtX4zXp9m5+3Z44gcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyUdXHudQOGphcaxw+uOTrFbbEj0wpPvh4yddqifqhvZNrzR3bknL25UdG69uvt1WePGzYdXPZrtV3YdkuBe3a0m/sG63/fth5zXR1i1avf6VXsmOXry2O1uPfiXmrPPEDAMiE4AcAkAnBDwAgE4IfAEAmBD8AgExUxa7edUftE60fc+aNyZ7Jff5a+n2a6qP1sVeemuyp+3O8p+aueSXff/FB5f3t2vqxhrJeD8rlpUnjo/UXR6d7ei8pROvbHrYo2fPDodeVNFdzpp7x6+TaCe88Jlof+eV7y3Z/KKdOdcOSa2d/4fJovVdNfOduCCFsbHo1Wv/mjM8le7Zf7YSJ1uCJHwBAJgQ/AIBMCH4AAJkQ/AAAMiH4AQBkQvADAMhEVRzncsuPpkXr3QtdynqfPomt6k989ufJnnVHx49z+ehjn032bPzboGh93id/0sx0XaPVDcX0S+hr65uauR60rsVXj0mu3TL+3Gh929oeJd+ntpD++21jMfUZiB8NE0L6WKet/DWaDqjQOf59svNv0t87Du65oeT7nLtmz2h9+7Md2dLWfKkCAMiE4AcAkAnBDwAgE4IfAEAmBD8AgExUxa7emzcOjNYP7rm25GvdXt85uXbB0g9G678fcVOyJ7UTePaYa9NDJDc7xnfuNufyl3dJrnW5+YGSr9dWGt//rmh93Q7pX4N+M+a01ji0gp2mpncNTrnwsGj9k4MeSvY8tGGHaL2mUEz2TNxqXrS+f7f4C+VDCOGzTx8arTcdmv75jFxzb3INKqlx39HR+vUjLyv5Whub0p+bP53/vmi9f/B1u6154gcAkAnBDwAgE4IfAEAmBD8AgEwIfgAAmRD8AAAyURXHuXzn4s9E6wd89bxkT/dC/MXUP1j80WRPl2PjOXlij08ne06+4fpo/UPdNyV7yumYvk8m13Z9ume0/ovnJyR7jh9y+9uc6K3ZtfPsaL22UEj2fHbGe1prHFpB4+PpP5uN8ZMfwjUDdkv3rHmx5BlW37NftL7/Drclez43NP5S+UvXDC/5/lBpm77xctmuNfovJybXRv3asS3thSd+AACZEPwAADIh+AEAZELwAwDIhOAHAJCJqtjVO+S8+C67jyz+crLnS9+/Llr/6y43pG8U32gavrx8fLJljy5rEis90vcpo9Tu5RBCmNBtS7w+/JbWGud1Zm3sk1w74KEjovWB07one2rDQ297Jtq3luzcrR29c3LtnO0uTayk/5xtVbOx5BmgkrZ8cK/k2h9G/yyxEj/1oTnDZqVPXaD98MQPACATgh8AQCYEPwCATAh+AACZEPwAADIh+AEAZKIqjnNJ6fGHucm183vHjwup/39/TPYc1ntR/FpDm3v5dPzYlnVN9cmO77ywf7Q+Z9reyZ7+j5bvRdtPfrF3cq3YuSla3+rhzsmewfesjdZrVqdnHrJ0fnINSvHSHv2Sa0Nq08e2pBx/5+ej9VHhgZKvBW1h/Snrk2sDa0s/tuWIZz4QrXf/2z+TPcWS70Jr8cQPACATgh8AQCYEPwCATAh+AACZEPwAADJR1bt6m9PvN/GduNf8ZnCy53fv+0i0/sKepe8MHHpb+mXzTY89Ea1vFdK7h+N7bVtm5IllvFhIz1bOmSFlXV3677c1ofSXyndemd7BDpXUaYfto/Uzd/5TWe+zfNqIaL3n5vRJGrQfnvgBAGRC8AMAyITgBwCQCcEPACATgh8AQCYEPwCATGR7nEtL1NwxL1offEfp13KUCbSNzf3Tn7amFrw6frt/bHk740Cradymb7R+UM+NZb1PwTewDs0TPwCATAh+AACZEPwAADIh+AEAZELwAwDIhF29QFXrMeLlknt+v2Hr5FrXu+dH6zY6UmmFx56K1ne67Zhkz9MfuCxaf+TV+mRPz0UbovXS98hTCZ74AQBkQvADAMiE4AcAkAnBDwAgE4IfAEAmBD8AgEw4zgXgDZ7b0j+51vTKK204Cbx1TfXxI1hGfHZesueAsGcL7vR4C3poLzzxAwDIhOAHAJAJwQ8AIBOCHwBAJgQ/AIBM2NUL8AYX/+1DybUR4d42nASgvDzxAwDIhOAHAJAJwQ8AIBOCHwBAJgQ/AIBMCH4AAJlwnAtQ1YYcPD+59vGwV7TuyBagWnniBwCQCcEPACATgh8AQCYEPwCATAh+AACZEPwAADIh+AEAZELwAwDIhOAHAJAJwQ8AIBOCHwBAJgQ/AIBMFIrFYrHSQwAA0Po88QMAyITgBwCQCcEPACATgh8AQCYEPwCATAh+AACZEPwAADIh+AEAZELwAwDIxP8H/lrAkhWkHqAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_iter = iter(x_train for x_train, _ in ds_train.take(9).cache().repeat())\n",
    "labels_iter = iter(y_train for _, y_train in ds_train.take(9).cache().repeat())\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(next(images_iter).numpy().astype(\"uint8\"))\n",
    "    plt.title(next(labels_iter).numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "\n",
    "Before training we need to preprocess the images.\n",
    "\n",
    "We start by normalizing the image pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image, label):\n",
    "    \"\"\"Normalize image pixels.\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255.0, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize train and test data\n",
    "ds_train = ds_train.map(normalize, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_eval = ds_eval.map(normalize, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.map(normalize, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))\n",
      "(TensorSpec(shape=(28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))\n",
      "(TensorSpec(shape=(28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))\n"
     ]
    }
   ],
   "source": [
    "# Print element spec after preprocessing\n",
    "print(ds_train.element_spec)\n",
    "print(ds_eval.element_spec)\n",
    "print(ds_test.element_spec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shapes are the same, `(28, 28, 1)`, but the type has changed, `dtype=tf.float32`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Dataset` API has some nice functionalities for speeding up the traning time.\n",
    "\n",
    "By caching the datasets we we will save some operations (like file opening and data reading) from being executed during each epoch, [reference](https://www.tensorflow.org/guide/data_performance#caching)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up training data\n",
    "\n",
    "First, we take the training data and apply the following steps:\n",
    "* cache it before shuffling for better performance\n",
    "* for true randomness, set shuffle buffer to full dataset size\n",
    "* batch elements of the dataset after shuffling to get unique batches at each epoch\n",
    "* prefetch to increase performace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache train data\n",
    "ds_train = ds_train.cache()\n",
    "\n",
    "# Shuffle data for true randomness and to reduce memory usage\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "\n",
    "# Set batch size\n",
    "ds_train = ds_train.batch(32)\n",
    "\n",
    "# Prefetch\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we take our evaluation and test data. We do similar steps but skip a few:\n",
    "* we don't need to shuffle the data\n",
    "* caching is done after batching because batches can be the same between epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set batch size\n",
    "ds_eval = ds_eval.batch(32)\n",
    "ds_test = ds_test.batch(32)\n",
    "\n",
    "# Cache test data\n",
    "ds_eval = ds_eval.cache()\n",
    "ds_test = ds_test.cache()\n",
    "\n",
    "# Prefetch\n",
    "ds_eval = ds_eval.prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "Next we instantiate the model and let it train for a number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classifier\n",
    "clf = KerasSeqClassifier(input_shape=(28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " zero_padding2d (ZeroPadding  (None, 34, 34, 1)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        1600      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                62730     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,458\n",
      "Trainable params: 64,394\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 23:16:59.663620: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-16 23:16:59.664195: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "/home/hojve/repos/github/deep-learning/deep-learning-fundamentals/.venv/lib/python3.10/site-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937/938 [============================>.] - ETA: 0s - loss: 0.2126 - sparse_categorical_accuracy: 0.9360"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 23:17:15.104604: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-05-16 23:17:15.105183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 16s 16ms/step - loss: 0.2125 - sparse_categorical_accuracy: 0.9360 - val_loss: 0.0980 - val_sparse_categorical_accuracy: 0.9682\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0782 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.0667 - val_sparse_categorical_accuracy: 0.9774\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0544 - sparse_categorical_accuracy: 0.9829 - val_loss: 0.0619 - val_sparse_categorical_accuracy: 0.9794\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0462 - sparse_categorical_accuracy: 0.9856 - val_loss: 0.0765 - val_sparse_categorical_accuracy: 0.9748\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0347 - sparse_categorical_accuracy: 0.9889 - val_loss: 0.0641 - val_sparse_categorical_accuracy: 0.9816\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "clf.call(ds_train=ds_train, ds_eval=ds_eval, epochs=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we evaluate on the test dataset which the model has never seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17/157 [==>...........................] - ETA: 0s - loss: 0.0539 - sparse_categorical_accuracy: 0.9890"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 23:18:16.047350: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "2023-05-16 23:18:16.048208: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0569 - sparse_categorical_accuracy: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.056865885853767395, 0.984000027179718]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.model.evaluate(ds_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model performs as good on the test dataset as it does on the validation dataset. This is encouraging and we probably hasn't overfitted on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
